# LLM Blog Generation App

This is a Streamlit web application that utilizes the LLaMA 2 7B model for generating blog content based on user-provided 
prompts. The app allows users to specify a topic, desired word count, and the target audience for the generated blog.

## Usage

  1. Clone the repository to your local machine:
     
    git clone https://github.com/your-username/llm-blog-generation-app.git
    cd llm-blog-generation-app
      
  2. Install the required dependencies:

    pip install -r requirements.txt

  3. Run the Streamlit app:

    streamlit run app.py

  4. Access the app in your web browser by following the link provided in the terminal.

## Features
  - Prompt-Based Generation: Users can input a topic, desired word count, and select the target audience for the blog.
  - Customizable: The app allows users to tailor the generated content based on specific job profiles or audience types.
  - LLaMA 2 7B Model: Utilizes the LLaMA 2 7B model for natural language generation, capable of producing coherent and contextually relevant text.

## File Structure
  - app.py: Main Python script containing the Streamlit application code.
  - requirements.txt: List of Python dependencies required to run the application.
  - models/: Directory containing the LLaMA 2 7B model file.
  - README.md: Documentation providing information about the project, usage instructions, and other details.

## Dependencies
  - Streamlit: Web application framework for Python.
  - LLaMA 2 7B Model: Large language model for natural language generation.
  - langchain: Python package for handling language generation tasks.

## [localhost:8501](Screenshot 2024-05-07 103525.png)
